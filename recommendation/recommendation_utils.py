from sklearn.metrics.pairwise import cosine_similarity
from torch_geometric.loader import LinkNeighborLoader
from torch_geometric.data import HeteroData
from gnn.gnn_model import GNN
from typing import Optional
from joblib import load
import pandas as pd
import numpy as np
import torch


def generate_upselling_list(
    products_df: pd.DataFrame,
    products_embeddings_df: pd.DataFrame,
    product_id: int,
    top_n: Optional[int] = 100,
    price_lower_bound: Optional[float] = 1.1,
    price_upper_bound: Optional[float] = 2.0,
) -> pd.DataFrame:
    """
    Generate a list of potential upselling products for a given product ID.

    This function identifies products that serve as a more premium alternative 
    to the specified product, offering similar functionality but at a higher price. 
    The recommendations are generated by first filtering for products in the 
    same category and subcategory as the specified product, and then selecting 
    the most similar products based on the cosine similarity of their description 
    embeddings.

    The resulting DataFrame contains the top recommendations within a specified 
    price range and similarity threshold.

    Parameters
    ----------
    products_df : pd.DataFrame
        DataFrame containing detailed information about each product, including 
        categories, subcategories, prices, and other relevant attributes.

    products_embeddings_df : pd.DataFrame
        DataFrame containing vector embeddings for each product, typically derived 
        from product descriptions, to enable similarity comparisons.

    product_id : int
        The unique identifier of the product for which upselling recommendations 
        are to be generated.

    top_n : Optional[int], default=100
        The maximum number of similar products to recommend as upsell options.

    price_lower_bound : Optional[float], default=1.1
        The minimum factor by which the recommended product's price should exceed 
        the original product's price. For example, a value of 1.1 indicates that 
        recommended products should be at least 10% more expensive.

    price_upper_bound : Optional[float], default=2.0
        The maximum factor by which the recommended product's price can exceed 
        the original product's price. A value of 2.0 restricts recommendations to 
        products that cost up to twice the original product's price.

    Returns
    -------
    pd.DataFrame
        A DataFrame containing the top upselling products based on similarity 
        and price criteria, along with their relevant details.
    """
    # Get product data
    product = products_df[products_df["product_id"] == product_id].iloc[0]
    
    # Get product metadata
    product_subcategory = product["product_subcategory"]
    product_category = product["product_category"]
    product_price = product["product_price"]

    # Get product embedding
    product_embedding = products_embeddings_df[products_embeddings_df["product_id"] == product_id].iloc[0, 1]
    product_embedding = product_embedding.reshape(1, -1) 

    # Calculate price range
    min_price = product_price * price_lower_bound
    max_price = product_price * price_upper_bound

    # Filter for candidate products
    candidates = products_df[
        (products_df["product_category"] == product_category) & 
        (products_df["product_subcategory"] == product_subcategory) &
        (products_df["product_price"] >= min_price) &
        (products_df["product_price"] <= max_price)
    ]

    # Get embeddings of candidates and calculate similarity
    if not candidates.empty:
        candidates_embeddings = products_embeddings_df[products_embeddings_df["product_id"].isin(candidates["product_id"])]
        candidates_embeddings = candidates_embeddings.set_index("product_id")
        candidates_embeddings["similarity"] = candidates_embeddings["embedding"].apply(
            lambda x: cosine_similarity(x.reshape(1, -1), product_embedding)[0][0]
        )
        return candidates_embeddings.sort_values(by="similarity", ascending=False)["similarity"].head(top_n).to_frame()

    # Return empty dataframe if no candidates are found
    return pd.DataFrame()


def generate_crosselling_list(
    products_df: pd.DataFrame,
    products_embeddings_df: pd.DataFrame,
    product_id: int,
    top_n: Optional[int] = 100,
) -> pd.DataFrame:
    """
    Generate a list of potential cross-selling products for a given product ID.

    This function identifies products that complement the specified product 
    (rather than serving as a premium alternative). Cross-selling recommendations 
    are generated by filtering for products in the same category as the specified 
    product and calculating similarity based on their description embeddings.

    The resulting DataFrame contains the top cross-selling recommendations based 
    on similarity, excluding the original product.

    Parameters
    ----------
    products_df : pd.DataFrame
        DataFrame containing detailed information about each product, including 
        categories, prices, and other relevant attributes.

    products_embeddings_df : pd.DataFrame
        DataFrame containing vector embeddings for each product, typically derived 
        from product descriptions, to enable similarity comparisons.

    product_id : int
        The unique identifier of the product for which cross-selling recommendations 
        are to be generated.

    top_n : Optional[int], default=100
        The maximum number of similar products to recommend as cross-sell options.

    Returns
    -------
    pd.DataFrame
        A DataFrame containing the top cross-selling products based on similarity 
        within the specified category, along with their similarity scores. 
        If no suitable candidates are found, returns an empty DataFrame.
    """
    # Get product data
    product = products_df[products_df["product_id"] == product_id].iloc[0]
    
    # Get product metadata
    product_category = product["product_category"]

    # Get product embedding
    product_embedding = products_embeddings_df[products_embeddings_df["product_id"] == product_id].iloc[0, 1]
    product_embedding = product_embedding.reshape(1, -1) 

    # Filter for candidate products
    candidates = products_df[(products_df["product_category"] == product_category) & (products_df["product_id"] != product_id)]

    # Get embeddings of candidates and calculate similarity
    if not candidates.empty:
        candidates_embeddings = products_embeddings_df[products_embeddings_df["product_id"].isin(candidates["product_id"])]
        candidates_embeddings = candidates_embeddings.set_index("product_id")
        candidates_embeddings["similarity"] = candidates_embeddings["embedding"].apply(
            lambda x: cosine_similarity(x.reshape(1, -1), product_embedding)[0][0]
        )
        return candidates_embeddings.sort_values(by="similarity", ascending=False)["similarity"].head(top_n).to_frame()

    # Return empty dataframe if no candidates are found
    return pd.DataFrame()


def generate_generic_recommendations(
    df: pd.DataFrame, purchase_embedding: np.ndarray, ids: list[int]
) -> pd.DataFrame:
    # Exclude already purchased items
    candidates = df[~df["product_id"].isin(ids)].copy()

    # Compute similarity
    candidates["similarity"] = candidates["embedding"].apply(  # type: ignore
        lambda x: cosine_similarity(
            x.reshape(1, -1), purchase_embedding.reshape(1, -1)
        )[0][0]
    )

    # Sort candidates by similarity
    candidates = candidates.sort_values("similarity", ascending=False)  # type: ignore
    return candidates


def load_graph_and_normalizers(path: str = "../data/transformed/"):

    graph_path = path + "graph.pth"
    product_scaler_path = path + "product_scaler.pkl"
    customer_scaler_path = path + "customer_scaler.pkl"
    edge_scaler_path = path + "edge_scaler.pkl"
    rev_edge_scaler_path = path + "rev_edge_scaler.pkl"

    data = torch.load(graph_path, weights_only=False)
    product_scaler = load(product_scaler_path)
    customer_scaler = load(customer_scaler_path)
    edge_scaler = load(edge_scaler_path)
    rev_edge_scaler = load(rev_edge_scaler_path)

    return data, product_scaler, customer_scaler, edge_scaler, rev_edge_scaler


def normalize_graph_features(
    data: HeteroData,
    product_scaler,
    customer_scaler,
    edge_scaler,
    rev_edge_scaler
) -> HeteroData:
    # normalize customer features
    customer_features_scaled = torch.tensor(customer_scaler.transform(data['customer'].x), dtype=torch.float32)
    data['customer'].x = customer_features_scaled

    # normalize product features
    product_features_scaled = torch.tensor(product_scaler.transform(data['product'].x[:, :2]), dtype=torch.float32)
    data['product'].x = torch.cat([product_features_scaled, data['product'].x[:, 2:]], dim=1)

    # normalize edge features
    edge_features_scaled = torch.tensor(edge_scaler.transform(data["customer", "bought", "product"].edge_attr), dtype=torch.float32)
    data["customer", "bought", "product"].edge_attr = edge_features_scaled

    # normalize rev edge features
    rev_edge_features_scaled = torch.tensor(rev_edge_scaler.transform(data["product", "rev_bought", "customer"].edge_attr), dtype=torch.float32)
    data["product", "rev_bought", "customer"].edge_attr = rev_edge_features_scaled

    return data


def prepare_batch_for_fitting(batch):
    products = batch["product"].x
    x_dict = batch.x_dict

    edge_index_dict = {
        ("customer", "bought", "product"): batch[("customer", "bought", "product")].edge_index,
        ("product", "rev_bought", "customer"): batch[("product", "rev_bought", "customer")].edge_index
    }

    edge_attr_dict = {
        ("customer", "bought", "product"): batch[("customer", "bought", "product")].edge_attr,
        ("product", "rev_bought", "customer"): batch[("product", "rev_bought", "customer")].edge_attr
    }

    edge_label_index = batch[("customer", "bought", "product")].edge_label_index
    labels = batch[("customer", "bought", "product")].edge_label

    return products, x_dict, edge_index_dict, edge_attr_dict, edge_label_index, labels


def create_edges_for_prediction(data: HeteroData, user_id: int, products: list[int]) -> HeteroData:
    data[("customer", "bought", "product")].edge_label_index = torch.tensor([[user_id] * len(products), products])
    data[("customer", "bought", "product")].edge_label = torch.ones(data[("customer", "bought", "product")].edge_label_index.shape[1])
    return data


def create_batch_for_prediction(data: HeteroData) -> HeteroData:
    torch.use_deterministic_algorithms(True)

    edge_label_index = (("customer", "bought", "product"), data[("customer", "bought", "product")].edge_label_index)
    edge_label = data[("customer", "bought", "product")].edge_label

    batches = LinkNeighborLoader(
        data,
        num_neighbors=[5] * 3,
        edge_label_index=edge_label_index,
        edge_label=edge_label,
        batch_size=data[("customer", "bought", "product")].edge_label.shape[0],
        shuffle=False
    )

    for batch in batches:
        return batch


def load_model(model_path, data, device):
    model = GNN(
        product_encoder_in_channels=770,
        product_encoder_hidden_channels=512,
        product_encoder_out_channels=128,
        gnn_encoder_hidden_channels=128,
        gnn_encoder_out_channels=64,
        graph_edge_dim=13,
        graph=data
    ).to(device)

    model.load_state_dict(torch.load(model_path, map_location=device))
    return model


def predict_with_model(model, batch, device, products_ids) -> dict[int, float]:
    model.to(device)
    batch.to(device)

    model.eval()
    products, x_dict, edge_index_dict, edge_attr_dict, edge_label_index, _ = prepare_batch_for_fitting(batch)
    
    with torch.no_grad():
        out = model(products, x_dict, edge_index_dict, edge_attr_dict, edge_label_index)
    
    probs = {}
    for i in range(len(products_ids)):
        probs[products_ids[i]] = out[i].item()
    
    return probs


def predict_with_gnn(
    user_id: int, 
    products_ids: list[int], 
    data_path: str =  "../data/transformed/",
    model_path: str = "../data/checkpoints/gnn_checkpoints/model_checkpoint_batch_28640.pth"
) -> dict[int, float]:
    data, product_scaler, customer_scaler, edge_scaler, rev_edge_scaler = load_graph_and_normalizers(data_path)
    data = normalize_graph_features(data, product_scaler, customer_scaler, edge_scaler, rev_edge_scaler)
    device = "cuda" if torch.cuda.is_available() else "cpu"
    data = create_edges_for_prediction(data, user_id, products_ids)
    batch = create_batch_for_prediction(data)
    model = load_model(model_path, data, device)
    probs = predict_with_model(model, batch, device, products_ids)
    return probs


def upsell_with_gnn(
    customer_id: int,
    product_id: int,
    data_path: str,
    model_path: str,
    products: pd.DataFrame,
    products_embeddings: pd.DataFrame,
    customers: pd.DataFrame,
    top_n: int
) -> dict[tuple[int, int], float]:

    # get upselling products
    upselling_list = generate_upselling_list(products, products_embeddings, product_id, top_n=top_n)
    upselling_products_ids = upselling_list.index.tolist()
    
    # get customer id in graph
    customer_id_mapping = {id_: idx for idx, id_ in enumerate(customers['customer_id'].values)}
    customer_id_in_graph = customer_id_mapping[customer_id]

    # get products ids in graph
    products_id_mapping = {id_: idx for idx, id_ in enumerate(products['product_id'].values)}
    products_ids = [products_id_mapping[id_] for id_ in upselling_products_ids]
    products_map = {
        upselling_products_ids[i]: products_ids[i]
        for i in range(len(upselling_products_ids))
    }

    # predict probabilities
    predictions = predict_with_gnn(
        customer_id_in_graph,
        products_ids,
        data_path=data_path,
        model_path=model_path
    )

    # format output 
    output = {
        (customer_id, upselling_products_ids[i]): predictions[products_ids[i]]
        for i in range(len(upselling_products_ids))
    }

    return output


def crossell_with_gnn(
    customer_id: int,
    product_id: int,
    data_path: str,
    model_path: str,
    products: pd.DataFrame,
    products_embeddings: pd.DataFrame,
    customers: pd.DataFrame,
    top_n: int
) -> dict[tuple[int, int], float]:

    # get upselling products
    crosselling_list = generate_crosselling_list(products, products_embeddings, product_id, top_n)
    crosselling_products_ids = crosselling_list.index.tolist()
    
    # get customer id in graph
    customer_id_mapping = {id_: idx for idx, id_ in enumerate(customers['customer_id'].values)}
    customer_id_in_graph = customer_id_mapping[customer_id]

    # get products ids in graph
    products_id_mapping = {id_: idx for idx, id_ in enumerate(products['product_id'].values)}
    products_ids = [products_id_mapping[id_] for id_ in crosselling_products_ids]
    products_map = {
        crosselling_products_ids[i]: products_ids[i]
        for i in range(len(crosselling_products_ids))
    }

    # predict probabilities
    predictions = predict_with_gnn(
        customer_id_in_graph,
        products_ids,
        data_path=data_path,
        model_path=model_path
    )

    # format output 
    output = {
        (customer_id, crosselling_products_ids[i]): predictions[products_ids[i]]
        for i in range(len(crosselling_products_ids))
    }

    return output
